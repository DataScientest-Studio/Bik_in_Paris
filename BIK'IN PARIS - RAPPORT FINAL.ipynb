{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIK'IN PARIS - ETUDE DU TRAFFIC CYCLISTE\n",
    "\n",
    "## PRESENTATION DU JEU DE DONNEES\n",
    "\n",
    "<br>\n",
    "\n",
    "L'objectif de notre étude est de réaliser une <b>analyse des données récoltées par des compteurs vélos</b> déployés par la mairie dans la ville de Paris afin de visualiser les horaires et les principales zones d’affluence.\n",
    "\n",
    "Le jeu de données est constitué de <u>771 788 lignes et de 9 variables</u>: <em>Identifiant du compteur, Nom du compteur, Identifiant du site de comptage, Nom du site de comptage, Comptage horaire, Date et heure de comptage, Date d'installation du site de comptage, Lien vers la photo du site de comptage</em> et <em>Coordonnées géographiques</em>.\n",
    "\n",
    "|    | Identifiant du compteur   | Nom du compteur                   |   Identifiant du site de comptage | Nom du site de comptage           |   Comptage horaire | Date et heure de comptage   | Date d'installation du site de comptage   | Lien vers photo du site de comptage                           | Coordonnées géographiques   |\n",
    "|---:|:--------------------------|:----------------------------------|----------------------------------:|:----------------------------------|-------------------:|:----------------------------|:------------------------------------------|:--------------------------------------------------------------|:----------------------------|\n",
    "|  0 | 100003096-SC              | 97 avenue Denfert Rochereau SO-NE |                       1.00003e+08 | 97 avenue Denfert Rochereau SO-NE |                  0 | 2019-09-01T06:00:00+02:00   | 2012-02-22                                | https://www.eco-visio.net/Photos/100003096/15765766519670.jpg | 48.83511,2.33338            |\n",
    "|  1 | 100003096-SC              | 97 avenue Denfert Rochereau SO-NE |                       1.00003e+08 | 97 avenue Denfert Rochereau SO-NE |                  0 | 2019-09-01T03:00:00+02:00   | 2012-02-22                                | https://www.eco-visio.net/Photos/100003096/15765766519670.jpg | 48.83511,2.33338            |\n",
    "|  2 | 100003096-SC              | 97 avenue Denfert Rochereau SO-NE |                       1.00003e+08 | 97 avenue Denfert Rochereau SO-NE |                  0 | 2019-09-01T04:00:00+02:00   | 2012-02-22                                | https://www.eco-visio.net/Photos/100003096/15765766519670.jpg | 48.83511,2.33338            |\n",
    "|  3 | 100003096-SC              | 97 avenue Denfert Rochereau SO-NE |                       1.00003e+08 | 97 avenue Denfert Rochereau SO-NE |                 16 | 2019-09-01T09:00:00+02:00   | 2012-02-22                                | https://www.eco-visio.net/Photos/100003096/15765766519670.jpg | 48.83511,2.33338            |\n",
    "|  4 | 100003096-SC              | 97 avenue Denfert Rochereau SO-NE |                       1.00003e+08 | 97 avenue Denfert Rochereau SO-NE |                  2 | 2019-09-01T05:00:00+02:00   | 2012-02-22                                | https://www.eco-visio.net/Photos/100003096/15765766519670.jpg | 48.83511,2.33338            |\n",
    "\n",
    "\n",
    "Les variables qui serviront principalement à mener à bien notre analyse sont le <em>comptage horaire</em> (notre variable cible), la <em>date et heure du comptage</em> et les <em>coordonnées géographiques</em>.\n",
    "\n",
    "Les données ont été récoltées de <b>septembre 2019 à septembre 2020</b>, et nous présente, pour chaque compteur, le nombre d'utilisateurs de vélibs qui sont passés devant ce compteur à chaque heure de cette année. \n",
    "\n",
    "Le prétraitement des données à été réalisé en plusieurs étapes à savoir:\n",
    "\n",
    " - Nous avons tout d'abord supprimé les valeurs manquantes grâce à la fonction dropna(). Nous avons opté pour la suppression des valeurs manquantes et non leur remplacement car elles ne correspondent qu’à 2% des données présentes dans notre jeu de données et ne possèdent donc pas de réel impact sur les résultats. Nous avons donc par la suite travaillé sur un jeu de données de 753 078 lignes.\n",
    " \n",
    " - Nous avons par la suite extrait l’heure, le jour de la semaine, le jour du mois, le mois et l’année de la variable <em>Date et heure de comptage</em> afin d'étudier la variation du comptage horaire en fonction de ces différentes variables.\n",
    " \n",
    " - Les jours étant automatiquement numérotés de 0 à 6, nous avons remplacé ces nombres par les jours de la semaine afin de permettre une interprétation plus facile des résultats.\n",
    " \n",
    " - Nous avons renommé la colonne <em>Comptage horaire</em> en <em>Comptage_horaire</em> pour faciliter le calcul du test statistique ANOVA\n",
    " \n",
    " - Enfin, nous avons extrait la longitude et la latitude des coordonnées géographiques afin de visualiser sur la carte de Paris présentée ci-dessous les zones où le comptage horaire a eu lieu.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emplacements géographiques des compteurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'carte_paris.png' style = 'height:500px'>\n",
    "Cette carte géographique de la ville de Paris nous permet de déterminer les emplacements de chaque compteur mentionné dans notre jeu de données, ainsi que leur poids de comptage horaire représenté par la taille de chaque point. \n",
    "\n",
    "On constate que les compteurs comptabilisant le plus grand nombre d'utilisateurs de vélibs sont principalement ceux situés dans l’hypercentre autour de Châtelet, près des principales gares, en bord de Seine et autour du périphérique, notamment près des grandes Portes. \n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "Nous allons dans un premier temps présenter nos principales visualisations du Comptage horaire en fonction du temps afin d'en étudier les corrélations, puis dans un second temps procéder à des expérimentations de Machine Learning pour tenter de déterminer le modèle de prédiction le plus efficace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA VISUALISATION ET ANALYSES STATISTIQUES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation du comptage horaire selon le mois"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation du comptage horaire par mois grâce à un barplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'comptage_mois2.png' style = 'height:500px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette première visualisation nous permet de constater que les mois de juin, juillet et septembre sont ceux qui connaissent le plus grand nombre de comptage horaire avec un moyenne située autour de 80: nous pouvons le justifier par le fait que les utilisateurs font davantage de vélo en été puisque le beau temps le permet, alors que la baisse du mois d'août s'explique plutôt par les départs en vacances. \n",
    "\n",
    "Mars, avril et novembre connaissent au contraire le plus petit nombre d’utilisateurs de vélibs, avec des moyennes de comptage horaire s'élevant respectivement à 30, 10 et 35. Concernant les mois de mars et d'avril, cela s’explique par la <u>crise sanitaire dû au Covid-19 et au confinement</u> qui a eu lieu. Quant au mois de novembre, cela s'explique plus simplement par la baisse de température qui désincite les utilisateurs à se déplacer en vélo.\n",
    "\n",
    "Nous constatons également une forte affluence inhabituelle pendant les mois de décembre et de janvier, malgré la baisse des températures, qui aurait donc logiquement provoqué une baisse de l’affluence des vélibs. Il s'agit en réalité de la période de <u>grève illimitée SNCF</u> qui a débuté le 5 décembre 2019 et qui a obligé les Parisiens à utiliser d'autres modes de transport dont les vélibs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation du comptage horaire d'un compteur en fonction de la date\n",
    "\n",
    "Dans cette section, nous avons sélectionné un compteur situé en zone de forte affluence, au \"89 boulevard de Magenta NO-SE\".\n",
    "\n",
    "Nous analysons alors l’affluence sur trois lundis de périodes différentes :\n",
    " - Le <u>lundi 9 décembre 2019</u> : lors des grèves SNCF \n",
    " - Le <u>lundi 18 novembre 2019</u> : journée classique\n",
    " - Le <u>lundi 23 mars 2020</u> : lors du début du confinement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'comptage_9dec2.png' style = 'height:300px'>\n",
    "On constate que le comptage horaire de cette journée de début de grève SNCF est très élevé, dépassant 500 comptages par heure en heure de pointe, contre une moyenne habituelle de 135 pour les mêmes horaires. \n",
    "<img src = 'comptage_18nov.png' style = 'height:300px'>\n",
    "Lors de ce lundi classique de travail, durant un mois de novembre où l’utilisation mensuelle est dans la moyenne, on constate que l’utilisation du compteur se situe autour de 300 en heure de pointe et autour de 100 durant le reste de la journée.\n",
    "<img src = 'comptage_23mars2.png' style = 'height:300px'>\n",
    "Notre dernier jour sélectionné est le premier lundi du confinement suite au Covid-19. On constate alors une très faible utilisation de vélos, sans différence notable entre les heures creuses et heures de pointe. L’utilisation moyenne du compteur se situe autour de 50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Etude de la corrélation entre le comptage horaire et le mois par le test ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|          |     df |      sum_sq |        mean_sq |      F |   PR(>F) |\n",
    "|:---------|-------:|------------:|---------------:|-------:|---------:|\n",
    "| mois     |      1 | 3.45443e+07 |    3.45443e+07 | 4688.8 |        0 |\n",
    "| Residual | 753076 | 5.54821e+09 | 7367.4         |  nan   |      nan |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La p-value (PR(>F)) est nulle, ce qui confirme que les mois ont un impact significatif sur la pratique du vélo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons alors conclure de ces premières visualisations ainsi que de notre test ANOVA que l'utilisation des vélibs varie fortement selon la saison et les évènements (grève, confinement, vacances...) survenant dans la ville de Paris. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation du comptage horaire selon le jour de la semaine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation du comptage horaire par jour de la semaine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'comptage_semaine1.png' style = 'height:400px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate que les vélos sont utilisés de manière homogène chaque jour de la semaine avec une moyenne de comptage horaire qui se situe autour de 60. \n",
    "\n",
    "Le comptage horaire nous permet également de conclure que les vélibs sont moins utilisés les week-ends. En effet, le comptage horaire moyen le samedi s'élève à 40 environ et à près de 50 pour le dimanche. \n",
    "\n",
    "Cette différence entre la semaine et le week-end nous amène à l'hypothèse que l'utilisation des vélibs varie en fonction des activités professionnelles et scolaires des habitants de la ville."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Etude de la corrélation entre le comptage horaire et le jour par le test ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|          |     df |      sum_sq |        mean_sq |       F |   PR(>F) |\n",
    "|:---------|-------:|------------:|---------------:|--------:|---------:|\n",
    "| jour     |      6 | 6.87764e+07 |    1.14627e+07 | 1565.52 |        0 |\n",
    "| Residual | 753071 | 5.51398e+09 | 7322           |  nan    |      nan |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La p-value (PR(>F)) est nulle, cela confirme que le jour de la semaine a un effet statistique significatif sur le comptage horaire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainsi, nous pouvons conclure de cette deuxième analyse ainsi que du test de corrélation ANOVA que l'utilisation des vélibs varie également en fonction de la période de la semaine. Les utilisateurs de vélibs semblent davantage utiliser les vélibs lors des journées de travail plutôt que pour leur loisirs en week-end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation du comptage horaire selon l’heure de la journée\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation du comptage horaire moyen selon l’heure de la journée\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'comptage_heure.png' style = 'height:400px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate que les vélos sont utilisés majoritairement durant les heures de pointe, c’est à dire de 8h à 10h ainsi que de 18h à 20h.\n",
    "Une moyenne de 110 utilisateurs par heure sont comptabilisés entre 8h et 10h et une moyenne de 135 utilisateurs entre 18h et 20h.\n",
    "\n",
    "Le reste de la journée indique une moyenne relativement stable et située autour de 70 comptages par heure alors que le graphique affiche sans surprise une baisse progressive par heure du nombre d'utilisateurs à partir de 20h et jusqu'au lendemain matin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation du comptage horaire de chaque jour de la semaine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'comptage_heure_barplot4.png' style = 'height:700px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette visualisation nous permet d'avoir une vision des moyennes de comptage horaire de chaque journée de la semaine et du week-end. \n",
    "\n",
    "On constate ainsi que les conclusions tirées grâce au graphique précédent sont dûes au jour de semaine uniquement, puisque les samedi et dimanche suivent une variation différente car ne connaissant pas de pic lors des heures de pointe. Cependant cette visualisation n'étant pas des plus lisibles, nous présentons également ci-dessous une visualisation représentant un graphique par jour de semaine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation du comptage horaire pour chaque jour de la semaine et selon l'heure\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'comptage_heure_par_jour7.png' style = 'height:700px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce graphique, qui présente chaque jour de semaine dans l'ordre, nous permet d'avoir une vision du comptage horaire par jour, et ainsi de mieux de nous rendre compte de la différence notable de variation entre la semaine et le week-end. \n",
    "\n",
    "Nous constatons encore une fois une très forte utilisation des vélos de 8h à 10h et de 18h à 20h uniquement du lundi au vendredi, pouvant aller jusqu'à 1200 passages d'utilisateurs de vélibs par heure sur ces horaires pour certains compteurs. Durant les autres plages horaires de la semaine, le comptage horaire semble uniforme.\n",
    "\n",
    "En week-end, le comptage horaire semble également uniforme entre le samedi et le dimanche. On observe une hausse progressive du nombre de passages de vélib jusqu'à atteindre en moyenne 700 passages autour de 18h avant de connaître une baisse progressive jusquau lendemain. \n",
    "\n",
    "Le comptage horaire varie donc de manière nettement différente entre la semaine et le weekd-end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Etude de la corrélation entre le comptage horaire et l’heure par le test ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|          |     df |      sum_sq |        mean_sq |       F |   PR(>F) |\n",
    "|:---------|-------:|------------:|---------------:|--------:|---------:|\n",
    "| C(heure) |     23 | 1.24848e+09 |    5.42816e+07 | 9431.09 |        0 |\n",
    "| Residual | 753054 | 4.33428e+09 | 5755.6         |  nan    |      nan |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La p-value (PR(>F)) est nulle, cela confirme que l'heure a un effet statistique significatif sur le comptage horaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainsi, nous pouvons tirer de ces visualisations de comptage horaire ainsi que du test ANOVA la conclusion que la période de la journée enraîne une variation notable sur l'utilisation de vélibs, puisqu'on parvient à nettement différencier les heures de départ et de retour du lieu de travail ainsi que les périodes plus calmes telles que la nuit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion sur ces visualisations\n",
    "<br/>\n",
    "\n",
    "Notre étude nous invite à utiliser les variables heure, jour et mois qui ont toutes trois un effet statistique très prononcé sur le comptage horaire pour anticiper les demandes des utilisateurs. La régularité du comptage horaire (renseigné toutes les heures sur le jeu de données) ainsi que la précision du lieu où se trouve chaque compteur nous permettent de livrer une analyse avec une certaine précision mais comportant toutefois des limites.\n",
    "\n",
    "En effet, les compteurs étant situés à des emplacements précis et ne couvrant pas la totalité de la capitale comme nous pouvons le constater sur notre carte d'introduction, cela ne nous permet pas de conclure sur les zones de forte ou de faible affluence.\n",
    "Aussi, l’exploitation de la variable mois peut s’avérer limitée pour visualiser le comportement du comptage horaire car les données ne représentent qu’une seule année. \n",
    "\n",
    "Un autre aspect important de cette analyse est la <b>présence de biais:</b> notamment la grève de transport et le confinement dû au Covid-19 qui, étant des évènements inhabituels, ne permettent pas de généraliser notre analyse sur les années suivantes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "# MODELISATION PAR MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction au Machine Learning\n",
    "<br />\n",
    "<br />\n",
    "Nous allons à présent procéder à des expérimentations de Machine Learning: anticiper le comptage horaire pour un jour et une heure de la semaine. \n",
    "Nous devrons ici utiliser des <b>méthodes de Régression</b> puisque nous avons uniquement des variables quantitatives à notre disposition. \n",
    "\n",
    "Pour mener à bien notre résolution de problème de Machine Learning, nous utilisons les variables listées ci-dessous:\n",
    " - <em>Identifiant du compteur</em>, pour garder l’identité des compteurs liés à chaque comptage horaire\n",
    " - <em>Comptage horaire</em>, qui est notre variable cible et qui nous sera donc essentielle pour la suite de notre analyse\n",
    " - <em>Date et heure de comptage</em> qui contient l’année, le mois, le jour et l’heure de chaque ligne de comptage horaire et qui nous sera d’une grande utilité pour préciser notre analyse\n",
    "\n",
    "Nous mettons ainsi volontairement de côté les variables ci-dessous: \n",
    " - <em>Nom du compteur, Identifiant du site de comptage</em> et <em>Nom du site de comptage</em> qui sont redondantes avec la variable gardée  <em>Identifiant du compteur</em>\n",
    " - <em>Date d’installation du site de comptage</em>, qui ne nous sert pas dans notre analyse\n",
    " - <em>Lien vers photo du site de comptage</em>, qui donne un lien URL et n’apporte donc aucune information utile pour la suite de notre analyse\n",
    " - <em>Cordonnées géographiques</em>, ne nous étant pas utile non plus pour résoudre notre problème de Machine Learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing de données\n",
    "\n",
    "<br />\n",
    "<br />\n",
    "Avant de démarrer nos expérimentations, nous procédons au preprocessing de nos données.\n",
    "\n",
    "Tout d’abord, nous commençons par <b>extraire le mois, le jour du mois, le jour de la semaine</b> (allant de 0 à 6 et représentant pour chaque journée, le jour de la semaine associé) ainsi que <b>l’heure</b> de notre variable <em>Date et heure de comptage</em>. \n",
    "\n",
    "Nous créons ensuite une boucle à l’aide des variables <em>Comptage horaire</em> et <em>Date et heure de comptage</em> afin d’extraire, pour chaque ligne de comptage horaire, le comptage des heures précédant cette dernière et enregistré sous chacune des variables <em>comptage_h-X</em>. La <b>fenêtre horaire</b> que l’on voudra observer sera défini par une variable fenêtre que l’on programmera successivement sur 3, 5 et 7 afin d’observer le modèle qui nous donne les résultats les plus pertinents.\n",
    "\n",
    "Nous procédons par la suite à une nouvelle suppression des valeurs manquantes afin de ne pas freiner la suite de notre analyse.\n",
    "\n",
    "En procédant à l’extraction de nos variables cibles et explicatives, nous sélectionnons donc en tant que variable cible le <b><em>comptage horaire</em></b> et en tant que variables explicatives, celles listées ci-dessous:\n",
    "\n",
    " - <em>Identifiant du compteur</em>\n",
    " - <em>Weekday, mois</em> et <em>heure</em>\n",
    " - Les variables <em>comptage_h-X</em>\n",
    "\n",
    "Voici ci-dessous un extrait des variables que nous utilisons pour la suite de notre rapport, avec une fenêtre ajustée à 5:\n",
    "<br />\n",
    "<br />\n",
    "\n",
    "|        | Identifiant du compteur   |   Comptage_horaire |   weekday |   mois |   heure |   comptage_h-1 |   comptage_h-2 |   comptage_h-3 |   comptage_h-4 |   comptage_h-5 |\n",
    "|-------:|:--------------------------|-------------------:|----------:|-------:|--------:|---------------:|---------------:|---------------:|---------------:|---------------:|\n",
    "| 131937 | 100042374-109042374       |                109 |         2 |      8 |      16 |             57 |             78 |            257 |              0 |             42 |\n",
    "| 496725 | 100056041-SC              |                 53 |         0 |      8 |      13 |             88 |             29 |             11 |             55 |             25 |\n",
    "| 471396 | 100056038-SC              |                 13 |         4 |      1 |      20 |            100 |             35 |             52 |            179 |             40 |\n",
    "| 357255 | 100047548-104047548       |                  7 |         6 |      5 |       8 |             10 |             18 |             26 |             22 |             44 |\n",
    "| 572754 | 100056326-103056326       |                  4 |         3 |      1 |      23 |              4 |             17 |              7 |              2 |              1 |\n",
    "  \n",
    "  \n",
    "<br />\n",
    "<br />\n",
    "Nous avons enfin procédé au découpage de notre jeu de données en données d’entraînement et de test. Nous souhaitons ici utiliser comme données d’entraînement les données correspondants aux <b>21 premiers jours de chaque mois</b> (ou aux 3 premières semaines) et comme données de test, les données survenants après le 21ème jour de chaque mois. Nous utilisons cette méthode pour avoir des données d’entraînement et de test gardant une certaine cohérence temporelle, contrairement au train_test_split qui sélectionnerait des données de manière aléatoire et donc non pertinentes. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exprérimentation Machine Learning\n",
    "<br/>\n",
    "<br/>\n",
    "Nous avons sélectionné pour notre expérimentation trois méthodes de Machine Learning:\n",
    "\n",
    " - <b>La Régression linéaire</b>\n",
    " - <b>Le Gradient Boosting Regressor</b>\n",
    " - <b>Le Random Forest Regressor</b>\n",
    "\n",
    "\n",
    "### Régression Linéaire\n",
    "<br/>\n",
    "\n",
    "Après avoir fait varier la fenêtre sur différentes valeurs à savoir 3, 5 et 7, le modèle a été instancié puis entraîné sur l'ensemble d'entraînement (X_train et y_train). Par la suite, a été déterminé respectivement : \n",
    " - L’erreur moyenne absolue du jeu d’entraînement (MAE train)\n",
    " - L’erreur moyenne absolue du jeu de test (MAE test)\n",
    " - L’erreur relative du jeu de test (=MAE sur le jeu de test / comptage moyen)\n",
    "\n",
    "Observons à présent les résultats pour chacune des fenêtres:\n",
    "\n",
    "\n",
    "#### Fenêtre = 3\n",
    "\n",
    "MAE train: 21.49480241855504   \n",
    "MAE test: 20.391301560019645\n",
    "\n",
    "Relative test error: 0.35931435011831153\n",
    "\n",
    "\n",
    "#### Fenêtre = 5\n",
    "\n",
    "MAE train: 21.405109067699964  \n",
    "MAE test: 20.33467288956354\n",
    "\n",
    "Relative test error: 0.3582412759011802\n",
    "\n",
    "\n",
    "#### Fenêtre = 7\n",
    "\n",
    "MAE train: 21.374116427049746  \n",
    "MAE test: 20.31097360560857\n",
    "\n",
    "\n",
    "Relative test error: 0.35781520803226163\n",
    "\n",
    "<br/>\n",
    "\n",
    "<u>Observations:</u> La Regression linéaire nous montre que les résultats entre les différentes fenêtres considérées sont presque égaux. Par ailleurs, ces résultats obtenus nous laissent penser que la performance du modèle ne varie pas selon les différentes valeurs que l'on attribue au comptage horaire des heures précédentes.\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Gradient Boosting Regressor\n",
    "<br/>\n",
    "\n",
    "Tout comme pour la Régression linéaire, nous faisons varier la fenêtre sur 3, 5 puis 7. En suivant le même entraînement que précédemment et en instanciant cette fois le GradientBoostingRegressor, voici les résultats que nous obtenons:\n",
    "\n",
    "\n",
    "#### Fenêtre = 3\n",
    "\n",
    "GBR MAE train 15.102000435778786  \n",
    "GBR MAE test 14.177302213047787\n",
    "\n",
    "GBR Relative test error: 0.249817703696755\n",
    "\n",
    "#### Fenêtre = 5\n",
    "\n",
    "GBR MAE train 15.10200043577875  \n",
    "GBR MAE test 14.177302213047744\n",
    "\n",
    "GBR Relative test error: 0.24981770369675424\n",
    "\n",
    "#### Fenêtre = 7\n",
    "\n",
    "GBR MAE train 15.102000435778768  \n",
    "GBR MAE test 14.177302213047767\n",
    "\n",
    "GBR Relative test error: 0.24981770369675466\n",
    "\n",
    "<br/>\n",
    "\n",
    "<u>Observations:</u> Les résultats du Gradient Boosting Regressor sont meilleurs que ceux de la Regression Linéaire. La MAE train et la MAE test présentent un très faible écart, ce qui signifie a priori que l'apprentissage est bon. Par ailleurs, on ne constate aucune différence notable entre les fenêtres 3, 5 et 7, cela nous amène à la conclusion que la performance du modèle ne varie pas significativement selon la visibilité que l'on donne à l'algorithme pour chaque comptage horaire.\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Random Forest Regressor\n",
    "<br/>\n",
    "\n",
    "Comme précédemment, afin de faire varier les résultats, nous faisons varier la fenêtre horaire destinée à ajuster les prédictions du modèle sur 3, 5 puis 7. \n",
    "\n",
    "<u>Pour chaque fenêtre:</u>\n",
    "\n",
    "Après avoir instancié notre modèle, nous testons les <b>hyperparamètres</b> suivants:\n",
    " - n_estimators: [100,300,500], \n",
    " - max_depth: [2,11,20],\n",
    " - min_samples_split: [2,50,100],\n",
    " - min_samples_leaf: [1,50,100]}\n",
    "\n",
    "Par la suite nous utilisons la classe <b>GridsearchCV</b> pour sélectionner l’ensemble de paramètres ayant la meilleure performance moyenne sur l’ensemble des échantillons.\n",
    "\n",
    "Après avoir sélectionné les paramètres les plus pertinents avec la fonction best_params_, nous les appliquons au modèle et observons la <b>MAE (Mean Absolute Error)</b> de ce modèle optimal avec:\n",
    " - L’erreur moyenne absolue du jeu d’entraînement\n",
    " - L’erreur moyenne absolue du jeu de test\n",
    " - L’erreur relative du jeu de test (=MAE sur le jeu de test / comptage moyen)\n",
    "\n",
    "<br/>\n",
    "Ce modèle s'avère être particulièrement long à exécuter. Notre fichier contenant 753 058 lignes après suppression des valeurs manquantes, nous avons calculé le temps nécessaire pour entraîner le modèle sans prendre en compte les paramètres: 451.52 secondes, soit <b>plus de 7 minutes</b>. \n",
    "\n",
    "Cela nous amènerait donc à <b>un temps de 50h pour entraîner ce modèle avec le GridSearchCV et donc en prenant en compte chacun des hyperparamètres que nous souhaitions tester</b>. Nous pouvons donc en conclure que Scikit Learn n'est pas le modèle adapté pour ce type de calcul.\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Visualisation de notre meilleur modèle: Gradient Boosting Regressor\n",
    "<br/>\n",
    "\n",
    "Dans cette dernière partie, nous allons afficher une visualisation nous permettant d'observer l'efficacité du modèle nous ayant apporté les meileurs scores: le Gradient Boosting Regressor. \n",
    "\n",
    "Nous choisissons de faire apparaître une visualisation sur un compteur: \"89 boulevard de Magenta NO-SE\" et une date: le jeudi 28 novembre 2019, date non biaisée.\n",
    "\n",
    "Nous ajustons ensuite notre fenêtre de comptage horaire sur 7, notre ajustage le plus large testé précédemment. Puis nous définissons à nouveau nos données d'entraînement contenant toutes les données de notre dataset mis à part celles que nous cherchons à prédire, et nos données de test correspondant à celles du compteur et de la date choisis. Après avoir entraîné notre modèle puis après avoir fait notre prédiction, nous obtenons la visualisation suivante:\n",
    "\n",
    "<img src = 'visu-predictions3.png' style = 'height:400px'>\n",
    "\n",
    "Cette visualisation nous permet d'observer que le modèle du Gradient Boosting Regressor nous donne des prédictions fiables lors des heures creuses mais ne permet pas de prédire avec précision le comptage horaire durant les heures de pointe. La différence entre le comptage horaire réel et les prédictions possède pour ces heures là une différence au moins égale à 50 comptages. Par ailleurs on observe également que les prédictions affichent en heure de pointe un résultat toujours inférieur au comptage réel. Cela est dû aux variations trop fortes du comptage horaire sur les heures de pointe entre chaque journée qui rend les prédictions moins fiables.\n",
    "\n",
    "Nous ne pouvons donc pas conclure que ce modèle soit particulièrement performant en semaine étant donné les fortes variations qui adviennent chaque matin et soir. \n",
    "\n",
    "<br/>\n",
    "\n",
    "Nous allons à présent visualiser les prédictions faites sur un jour de week-end afin de comparer nos résultats avec ceux du jour de semaine obtenus précédemment. En suivant le même procédé que celui développé plus haut, voici la visualisation obtenue:\n",
    "\n",
    "<img src = 'visu-predictions-samedi.png' style = 'height:400px'>\n",
    "\n",
    "La tendance générale reste globalement semblable entre les prédictions et la réalité, mais nous ne pouvons pas pour autant conclure que la prédiction soit particulièrement fiable: les prédictions faites par le modèle présentent un écart souvent supérieur à 50 comptages durant la journée et pouvant aller jusqu'à plus de 150 comptages d'écartssur certaines heures.\n",
    "\n",
    "Ainsi, nous pouvons conclure que malgré des prédictions parfois fidèles à la réalité, le modèle du Gradient Boosting Regressor n'est pas pour autant un modèle complètement fiable et ne parvient pas à donner une prédiction semblable au comptage horaire réel.\n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion sur le Machine Learning\n",
    "<br/>\n",
    "\n",
    "Nous pouvons conclure de nos expérimentations que le Gradient Boosting Regressor semble nous apporter de meilleurs résultats que la Régression Linéaire pour notre problème de Machine Learning. Pourtant, malgré ces résutats plus encourageants, la visualisation des prédictions faites grâce à ce modèle du Gradient Boosting Regressor en semaine nous montre ses limites: la prédiction faite est certes fiable sur les heures creuses mais beaucoup moins sur les heures de pointe. En week-end, les prédictions faites restent également peu fiables et montrent des disparités avec la réalité.\n",
    "\n",
    "Aussi, nos changements de fenêtres entraînés sur 3, 5 puis 7 nous permettent de conclure que le modèle n'est pas plus ou moins performant selon la visibilité qu'on lui donne sur les comptages horaire des heures précédentes. \n",
    "\n",
    "Aussi, nous constatons que le GridSearchCV n'est pas une méthode efficace pour résoudre notre problème de Machine Learning sous Scikit Learn avec un fichier contenant un nombre important de données. Il serait donc préférable d'utiliser le framewok Pyspark pour entraîner ce modèle. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importation des packages, lecture et prétraitement du jeu de données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Installation et importation des packages\n",
    "!pip install geopandas\n",
    "!pip3 install contextily\n",
    "!pip install tabulate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopandas\n",
    "import contextily as ctx\n",
    "import statsmodels.api\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Lecture du DataFrame\n",
    "df=pd.read_csv(\"comptage-velo-donnees-compteurs.csv\", sep=';')\n",
    "\n",
    "#Suppression des valeurs manquantes\n",
    "df = df.dropna()\n",
    "\n",
    "#Extraction de nouvelles variables \"année\", \"mois\", \"weekday\", \"jour\" et \"heure\" de la variable \"Date et heure de comptage\"\n",
    "df['Date et heure de comptage'] = pd.to_datetime(df['Date et heure de comptage'], format='%Y-%m-%dT%H:%M:%S', utc = True)\n",
    "\n",
    "df['année'] = df['Date et heure de comptage'].dt.year\n",
    "df['weekday'] = df['Date et heure de comptage'].dt.weekday\n",
    "df['jour'] = df['Date et heure de comptage'].dt.day\n",
    "df['mois'] = df['Date et heure de comptage'].dt.month\n",
    "df['heure'] = df['Date et heure de comptage'].dt.hour\n",
    "\n",
    "#Remplacement des modalités de la variable \"jour\" par leurs noms respectifs\n",
    "df['weekday'] = df['weekday'].replace([0,1,2,3,4,5,6],['Lundi', 'Mardi', 'Mercredi', 'Jeudi', 'Vendredi', 'Samedi', 'Dimanche'])\n",
    "\n",
    "# Renommage de la variable \"Comptage horaire\" pour permettre le test ANOVA \n",
    "df = df.rename(columns = {'Comptage horaire': 'Comptage_horaire'})\n",
    "\n",
    "# Extraction de la latitude et la longitude à partir de la variable \"Coordonnées Geographiques\"\n",
    "extraire_latitude = lambda ligne: ligne['Coordonnées géographiques'].split(',')[0]\n",
    "extraire_longitude = lambda ligne: ligne['Coordonnées géographiques'].split(',')[1]\n",
    "\n",
    "#Transformation de la colonne « Date et heure de comptage » en deux colonnes\n",
    "df = df.join(df['Date et heure de comptage'].str.split('T', 1, expand=True).rename(columns={0:'Date du comptage', 1:'Heure du comptage'}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation des compteurs sur la carte de Paris grâce à GeoPandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application des fonctions sur chaque ligne du dataframe\n",
    "df['X'] = df.apply(extraire_latitude, axis = 1)\n",
    "df['Y'] = df.apply(extraire_longitude, axis = 1)\n",
    "\n",
    "# Création du GeoDataFrame pour la visualisation\n",
    "gdf = geopandas.GeoDataFrame(\n",
    "    df, geometry=geopandas.points_from_xy(df['Y'], df['X']))\n",
    "gdf.head()\n",
    "\n",
    "# Coordinate reference system\n",
    "crs={'init':'epsg:4326'}\n",
    "\n",
    "# Traçage des points du geodataframe\n",
    "ax = gdf.plot(figsize=(10, 10), alpha=0.5, markersize = 'Comptage_horaire')\n",
    "plt.axis('off')\n",
    "\n",
    "# Ajout de la carte de fond avec le module contextily\n",
    "ctx.add_basemap(ax, crs = crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA VISUALISATION\n",
    "#### Création et enregistrement des barplot de l'analyse selon le mois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création du graphique\n",
    "plt.figure(figsize=(14,8))\n",
    "sns.barplot(x=\"mois\", y=\"Comptage_horaire\" ,data=df)\n",
    "plt.ylabel(\"comptage horaire\")\n",
    "plt.axvspan(0.1,0.15, color='red')\n",
    "plt.axvspan(10.5,10.55, color='red')\n",
    "plt.text(-0.9, 80, 'Grèves',  fontsize=15, color='red')\n",
    "plt.text(10.9, 80, 'Grèves',  fontsize=15, color='red')\n",
    "plt.axvspan(2,2.05, color='blue')\n",
    "plt.axvspan(3.8,3.85, color='blue')\n",
    "plt.text(2.1, 80, 'Confinement',fontsize=15, color='blue')\n",
    "plt.xticks(np.arange(12),['Janvier 2020', 'Février 2020', 'Mars 2020', 'Avril 2020', 'Mai 2020', 'Juin 2020', 'Juillet 2020','Août 2020','Septembre 2019 & 2020','Octobre 2019','Novembre 2019','Décembre 2019'],rotation=45)\n",
    "plt.title(\"Comptage horaire selon le mois\");\n",
    "\n",
    "# Get Current Figure\n",
    "fig = plt.gcf()\n",
    "# Enregistrer la figure\n",
    "fig.savefig(\"comptage_mois2.png\", dpi = 300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création des barplot des 3 lundis:\n",
    "\n",
    "#Barplot de grève SNCF (9 décembre 2019)\n",
    "\n",
    "compteur_forte_affluence = df[(df[\"Nom du compteur\"] == '89 boulevard de Magenta NO-SE') & (df[\"Date du comptage\"] == \"2019-12-09\")]\n",
    "sns.barplot(x=\"heure\", y=\"Comptage_horaire\" ,data=compteur_forte_affluence)\n",
    "plt.ylabel(\"comptage horaire\")\n",
    "plt.xlabel(\"heure\")\n",
    "plt.title(\"Comptage horaire du lundi 9 décembre 2019 (grève)\");\n",
    "\n",
    "# Get current figure\n",
    "fig = plt.gcf()\n",
    "# Enregistrer la figure\n",
    "fig.savefig(\"comptage_9dec2.png\", dpi = 300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Barplot de journée classique (28 novembre 2019)\n",
    "\n",
    "compteur_forte_affluence_nov = df[(df[\"Nom du compteur\"] == '89 boulevard de Magenta NO-SE') & (df[\"Date du comptage\"] == \"2019-11-18\")]\n",
    "sns.barplot(x=\"heure\", y=\"Comptage_horaire\" ,data=compteur_forte_affluence_nov)\n",
    "plt.ylabel(\"comptage horaire\")\n",
    "plt.xlabel(\"heure\")\n",
    "plt.title(\"Comptage horaire du lundi 18 novembre 2019\")\n",
    "plt.ylim(0,600);\n",
    "\n",
    "# Get current figure\n",
    "fig = plt.gcf()\n",
    "# Enregistrer la figure\n",
    "fig.savefig(\"comptage_28nov2.png\", dpi = 300)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Barplot de journée de confinement (23 mars 2020)\n",
    "\n",
    "compteur_forte_affluence_avril = df[(df[\"Nom du compteur\"] == '89 boulevard de Magenta NO-SE') & (df[\"Date du comptage\"] == \"2020-03-23\")]\n",
    "sns.barplot(x=\"heure\", y=\"Comptage_horaire\" ,data=compteur_forte_affluence_avril)\n",
    "plt.ylabel(\"comptage horaire\")\n",
    "plt.xlabel(\"heure\")\n",
    "plt.title(\"Comptage horaire du lundi 23 mars 2020 (confinement)\")\n",
    "plt.ylim(0,600);\n",
    "\n",
    "# Get current figure\n",
    "fig = plt.gcf()\n",
    "# Enregistrer la figure\n",
    "fig.savefig(\"comptage_23mars2.png\", dpi = 300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test ANOVA Comptage horaire - mois\n",
    "result = statsmodels.formula.api.ols('Comptage_horaire ~ mois', data = df).fit()\n",
    "table = statsmodels.api.stats.anova_lm(result)\n",
    "\n",
    "#Impression pour copier coller\n",
    "print(table.to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Création et enregistrement du barplot de l'analyse selon le jour de la semaine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création du graphique\n",
    "sns.barplot(x=\"weekday\", \n",
    "            y=\"Comptage_horaire\" , \n",
    "            order=['Lundi', 'Mardi', 'Mercredi', 'Jeudi', 'Vendredi', 'Samedi', 'Dimanche'], \n",
    "            data = df, palette=\"hls\")\n",
    "plt.title(\"Comptage horaire selon le jour\")\n",
    "\n",
    "# Get Current Figure\n",
    "fig = plt.gcf()\n",
    "# Enregistrer la figure\n",
    "fig.savefig(\"comptage_semaine1.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test ANOVA Comptage horaire - jour de semaine\n",
    "result = statsmodels.formula.api.ols('Comptage_horaire ~ weekday', data = df).fit()\n",
    "table = statsmodels.api.stats.anova_lm(result)\n",
    "\n",
    "#Impression pour copier coller\n",
    "print(table.to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Création des visualisations de l'analyse selon l'heure de la journée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création du graphique moyen\n",
    "plt.figure(figsize=(30,15))\n",
    "sns.barplot(x=\"heure\", y=\"Comptage_horaire\" ,data=df)\n",
    "plt.ylabel(\"Comptage horaire\", size=30)\n",
    "plt.xlabel(\"heure\", size=30)\n",
    "plt.yticks(size=20)\n",
    "plt.xticks(size=20)\n",
    "plt.title(\"Comptage horaire par heure\", size=30);\n",
    "\n",
    "# Get Current Figure\n",
    "fig = plt.gcf()\n",
    "# Enregistrer la figure\n",
    "fig.savefig(\"comptage_heure.png\", dpi = 400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création du barplot avec chaque jour de la semaine séparé\n",
    "plt.figure(figsize=(30,15))\n",
    "sns.barplot(x=\"heure\", y=\"Comptage_horaire\", hue=\"weekday\",\n",
    "            hue_order=['Lundi', 'Mardi', 'Mercredi', 'Jeudi', 'Vendredi', 'Samedi', 'Dimanche'] ,data=df,\n",
    "           palette=\"muted\")\n",
    "plt.ylabel(\"comptage horaire\")\n",
    "plt.xlabel(\"heure\")\n",
    "plt.title(\"Comptage horaire selon l'heure\");\n",
    "\n",
    "# Get Current Figure\n",
    "fig = plt.gcf()\n",
    "# Enregistrer la figure\n",
    "fig.savefig(\"comptage_heure_barplot4.png\", dpi = 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création du catplot avec un jour de la semaine par graphique\n",
    "sns.catplot(x = 'heure', \n",
    "            y=\"Comptage_horaire\", \n",
    "            estimator=sum, \n",
    "            col_order = ['Lundi', 'Mardi', 'Mercredi', 'Jeudi', 'Vendredi', 'Samedi', 'Dimanche'], \n",
    "            col = 'jour', \n",
    "            data = df, \n",
    "            col_wrap=3);\n",
    "plt.xticks([0, 6, 9, 12, 15, 18, 21, 24],['Minuit', '6h', '9h', '12h', '15h', '18h','21h', 'Minuit']);\n",
    "\n",
    "# Get Current Figure\n",
    "fig = plt.gcf()\n",
    "# Enregistrer la figure\n",
    "fig.savefig(\"comptage_heure_par_jour7.png\", dpi = 300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test ANOVA Comptage horaire - heure\n",
    "result = statsmodels.formula.api.ols('Comptage_horaire ~ C(heure)', data = df).fit()\n",
    "table = statsmodels.api.stats.anova_lm(result)\n",
    "\n",
    "#Impression pour copier coller\n",
    "print(table.to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création des variables \"comptage_h-X\" des heures précédant chaque comptage horaire\n",
    "fenetre = 3 #ou 5 ou 7\n",
    "nom_colonnes = ['comptage_h-' + str(i+1) for i in range(fenetre)]\n",
    "for i in range(fenetre):\n",
    "  df[nom_colonnes[i]] = np.nan\n",
    "for compteur in df['Identifiant du compteur'].unique():\n",
    "  df2 = df.loc[df['Identifiant du compteur'] == compteur].sort_values(by = 'Date et heure de comptage')\n",
    "  for i in range(fenetre):\n",
    "    df.loc[df2.index[i+1:], nom_colonnes[i]] = df2.loc[df2.index[:len(df2)-(i+1)], 'Comptage_horaire'].values\n",
    "    \n",
    "#Suppression des nouvelles valeurs manquantes\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition de la variable cible et des variables explicatives\n",
    "variables_explicatives = ['Identifiant du compteur', \n",
    "                          'weekday',  \n",
    "                          'mois',    \n",
    "                          'heure', \n",
    "                         'comptage_h-1',\n",
    "                         'comptage_h-2',\n",
    "                         'comptage_h-3']\n",
    "                        #'comptage_h-4', selon fenêtre instanciée\n",
    "                        #'comptage_h-5', selon fenêtre instanciée\n",
    "                        #'comptage_h-6', selon fenêtre instanciée\n",
    "                        #'comptage_h-7'] selon fenêtre instanciée \n",
    "\n",
    "variable_cible = ['Comptage_horaire']\n",
    "\n",
    "X = df[variables_explicatives]\n",
    "X = pd.get_dummies(X)\n",
    "y = df[variable_cible]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des données d'entraînement (21 premiers jours de chaque mois) et des données de test\n",
    "X_train = X[df['jour'] <= 21]\n",
    "X_test = X[df['jour'] > 21]\n",
    "\n",
    "y_train = y[df['jour'] <= 21]\n",
    "y_test = y[df['jour'] > 21]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcul de la Regression Linéaire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciation du Regresseur\n",
    "lr =  LinearRegression()\n",
    "\n",
    "# Entraînement du modèle sur l'ensemble d'entraînement \n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Evaluation de la baseline\n",
    "y_pred_train = lr.predict(X_train)\n",
    "y_pred_test = lr.predict(X_test)\n",
    "\n",
    "#Affichage de la MAE pour déterminer l'efficacité du modèle\n",
    "print(\"MAE train\", mean_absolute_error(y_train, y_pred_train))\n",
    "print(\"MAE test\", mean_absolute_error(y_test, y_pred_test))\n",
    "\n",
    "comptage_moyen = df['Comptage_horaire'].mean()\n",
    "print(\"\\nRelative test error:\", mean_absolute_error(y_test, y_pred_test)/comptage_moyen)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcul du Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entraînement du Regresseur:\n",
    "gbr = GradientBoostingRegressor()\n",
    "\n",
    "# Entraînement du modèle sur l'ensemble d'entraînement \n",
    "gbr.fit(X_train, y_train)\n",
    "\n",
    "#Evaluation de la baseline:\n",
    "y_pred_train = gbr.predict(X_train)\n",
    "y_pred_test = gbr.predict(X_test)\n",
    "\n",
    "print(\"GBR MAE train\", mean_absolute_error(y_train, y_pred_train))\n",
    "print(\"GBR MAE test\", mean_absolute_error(y_test, y_pred_test))\n",
    "\n",
    "comptage_moyen = df['Comptage_horaire'].mean()\n",
    "print(\"\\nGBR Relative test error:\", mean_absolute_error(y_test, y_pred_test)/comptage_moyen)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcul du Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciation du Regresseur\n",
    "rfr = RandomForestRegressor()\n",
    "\n",
    "#Définition des paramètres\n",
    "params_rfr={'n_estimators': [100,300,500], \n",
    "            'max_depth': [2,11,20],\n",
    "           'min_samples_split': [2,50,100],\n",
    "           'min_samples_leaf': [1,50,100]}\n",
    "\n",
    "#Utilisation d'un GridsearchCV pour déterminer les best parametors\n",
    "gridcv=GridSearchCV(rfr, param_grid=params_rfr, scoring='neg_mean_absolute_error')\n",
    "\n",
    "gridcv.fit(X_train, y_train)\n",
    "\n",
    "pd.DataFrame(gridcv.cv_results_)[['params', 'mean_test_score', 'std_test_score']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Affichage des best parameters:\n",
    "print(f'Best Parameters: {gridcv.best_params_}')\n",
    "\n",
    "y_pred_train = gridcv.predict(X_train)\n",
    "y_pred_test = gridcv.predict(X_test)\n",
    "\n",
    "#Affichage de la MAE pour déterminer l'efficacité du modèle\n",
    "print(\"MAE train\", mean_absolute_error(y_train, y_pred_train))\n",
    "print(\"MAE test\", mean_absolute_error(y_test, y_pred_test))\n",
    "\n",
    "comptage_moyen = df['Comptage_horaire'].mean()\n",
    "print(\"\\nRelative test error:\", mean_absolute_error(y_test, y_pred_test)/comptage_moyen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcul du temps nécessaire à l'entraînement du modèle Random Forest Regressor\n",
    "import time\n",
    "t = time.time() # heure actuelle\n",
    "\n",
    "rfr = RandomForestRegressor()\n",
    "\n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "temps = time.time() - t  # Le temps qu'il a fallu pour faire l'entraînement.\n",
    "print(\"Il a fallu\", temps, \"secondes pour entraîner le modèle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualisation de notre meilleur modèle pour comparer nos prédictions à la réalité pour une journée et un compteur précis\n",
    "# Pour la journée du jeudi 28 novembre 2019\n",
    "\n",
    "# Définition des données d'entraînement et des données de test (un seul compteur et une date)\n",
    "X_train = X[(df['Nom du compteur'] != \"89 boulevard de Magenta NO-SE\") & (df[\"Date du comptage\"] != \"2019-11-28\")]\n",
    "X_test = X[(df['Nom du compteur'] == \"89 boulevard de Magenta NO-SE\") & (df[\"Date du comptage\"] == \"2019-11-28\")]\n",
    "\n",
    "y_train = y[(df['Nom du compteur'] != \"89 boulevard de Magenta NO-SE\") & (df[\"Date du comptage\"] != \"2019-11-28\")]\n",
    "y_test = y[(df['Nom du compteur'] == \"89 boulevard de Magenta NO-SE\") & (df[\"Date du comptage\"] == \"2019-11-28\")]\n",
    "\n",
    "#Entraînement d'une baseline:\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "\n",
    "#Evaluation de la baseline:\n",
    "y_pred_test = gbr.predict(X_test)\n",
    "\n",
    "#Création d'un tableau contenant uniquement le compteur et la date souhaités\n",
    "df_date = df[(df['Nom du compteur'] == \"89 boulevard de Magenta NO-SE\") & (df[\"Date du comptage\"] == \"2019-11-28\")]\n",
    "\n",
    "#Visualisation des prédictions et du comptage horaire réel\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.scatter('heure', 'Comptage_horaire', data=df_date, label='Comptage horaire réel')\n",
    "plt.scatter(df_date[['heure']], y_pred_test,color='orange', label='Prédictions')\n",
    "plt.title('Relation entre le comptage horaire et l‘heure de la journée du 28/11/19')\n",
    "plt.ylabel('Comptage horaire')\n",
    "plt.xlabel('Heure')\n",
    "plt.legend();\n",
    "\n",
    "# Get current figure\n",
    "fig = plt.gcf()\n",
    "# Enregistrer la figure\n",
    "fig.savefig(\"visu-predictions.png\", dpi = 300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pour la journée du samedi 12 octobre 2019\n",
    "\n",
    "#Création d'un tableau contenant uniquement le compteur et la date souhaités\n",
    "df_date3 = df[(df['Nom du compteur'] == \"89 boulevard de Magenta NO-SE\") & (df[\"Date du comptage\"] == \"2019-10-12\")]\n",
    "\n",
    "# Définition des données d'entraînement et des données de test (un seul compteur et une date)\n",
    "X_train = X[(df['Nom du compteur'] != \"89 boulevard de Magenta NO-SE\") & (df[\"Date du comptage\"] != \"2019-10-12\")]\n",
    "X_test = X[(df['Nom du compteur'] == \"89 boulevard de Magenta NO-SE\") & (df[\"Date du comptage\"] == \"2019-10-12\")]\n",
    "\n",
    "y_train = y[(df['Nom du compteur'] != \"89 boulevard de Magenta NO-SE\") & (df[\"Date du comptage\"] != \"2019-10-12\")]\n",
    "y_test = y[(df['Nom du compteur'] == \"89 boulevard de Magenta NO-SE\") & (df[\"Date du comptage\"] == \"2019-10-12\")]\n",
    "\n",
    "#Entraînement d'une baseline:\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "\n",
    "#Evaluation de la baseline:\n",
    "y_pred_test = gbr.predict(X_test)\n",
    "\n",
    "#Afficher plot entre comptage horaire par heure et prédictions\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.scatter('heure', 'Comptage_horaire', data=df_date3, label='Comptage horaire réel')\n",
    "plt.scatter(df_date3[['heure']], y_pred_test, color='orange', label='Prédictions')\n",
    "plt.title('Comptage horaire du 89 Boulevard de Magenta le samedi 12/10/19')\n",
    "plt.ylabel('Comptage horaire')\n",
    "plt.xlabel('Heure')\n",
    "plt.legend();\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "nbTranslate": {
   "displayLangs": [],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "fr",
   "targetLang": "en",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
